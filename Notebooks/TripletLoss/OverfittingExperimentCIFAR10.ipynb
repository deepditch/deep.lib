{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from Models.selective_sequential import *\n",
    "from Loss.triplet_regularized import *\n",
    "from session import *\n",
    "from LR_Schedule.cyclical import Cyclical\n",
    "from LR_Schedule.cos_anneal import CosAnneal\n",
    "from LR_Schedule.lr_find import lr_find\n",
    "from callbacks import *\n",
    "from validation import *\n",
    "import Datasets.ImageData as ImageData\n",
    "from Transforms.ImageTransforms import *\n",
    "import util\n",
    "from session import LossMeter, EvalModel\n",
    "from Layers.flatten import Flatten\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.set_device(0); torch.backends.cudnn.benchmark=True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))])\n",
    "\n",
    "fulltrainset = torchvision.datasets.CIFAR10(root='/media/drake/MX500/Datasets/cifar-10/train', train=True,\n",
    "                                        download=True, transform=transform)\n",
    "trainset = torch.utils.data.dataset.Subset(fulltrainset, np.arange(3200))\n",
    "\n",
    "fullvalset = torchvision.datasets.CIFAR10(root='/media/drake/MX500/Datasets/cifar-10/test', train=False,\n",
    "                                       download=True, transform=transform)\n",
    "valset = torch.utils.data.dataset.Subset(fullvalset, np.arange(3200))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(fulltrainset, batch_size=32, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(fullvalset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "resnet = torchvision.models.resnet18(pretrained=False)\n",
    "num_ftrs = resnet.fc.in_features\n",
    "resnet.fc = nn.Sequential()\n",
    "\n",
    "#model = SelectiveSequential(\n",
    "#    ['act1', 'act2', 'out'],\n",
    "#    {'conv32a': resnet,\n",
    "#       \n",
    "#     'fc1': nn.Linear(num_ftrs, 1000),\n",
    "#     'act1': nn.ReLU(True),\n",
    "#     #'drop1': nn.Dropout(.05),\n",
    "#     'fc2': nn.Linear(1000, 1000),\n",
    "#     'act2': nn.ReLU(True),\n",
    "#     #'drop1': nn.Dropout(.05),\n",
    "#     'out': nn.Linear(1000, 10)})\n",
    "\n",
    "model = SelectiveSequential(\n",
    "    ['act64', 'act1', 'out'],\n",
    "    {'conv64': nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
    "     'act64': nn.ReLU(True),\n",
    "     \n",
    "     'max1': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'conv192': nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "     'act192': nn.ReLU(True),\n",
    "    \n",
    "     'max2': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'conv384': nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "     'act384': nn.ReLU(True),\n",
    "     \n",
    "     'conv256a': nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "     'act256a': nn.ReLU(True),\n",
    "     \n",
    "     'conv256b': nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "     'act256b': nn.ReLU(True),\n",
    "     \n",
    "     'max3': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     # 'avgpool': nn.AdaptiveAvgPool2d((6, 6)),\n",
    "    \n",
    "     'flatten': Flatten(),\n",
    "     'fc1': nn.Linear(4 * 4 * 256, 2048),\n",
    "     'act1': nn.ReLU(True),\n",
    "     'fc2': nn.Linear(2048, 2048),\n",
    "     'act2': nn.ReLU(True),\n",
    "     'out': nn.Linear(2048, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = TripletRegularizedCrossEntropyLoss(0, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = Session(model, criterion, optim.AdamW, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validator = EmbeddingSpaceValidator(valloader, 2, CustomOneHotAccuracy)\n",
    "lr_scheduler = CosAnneal(len(trainloader) * 60, T_mult=1, lr_min=1e-7)\n",
    "schedule = TrainingSchedule(trainloader, [lr_scheduler, validator])\n",
    "sess.train(schedule, 60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(validator.val_accuracies), \" Best validation accuracy without reg\")\n",
    "print(np.max(validator.train_accuracies), \" Best train accuracy without reg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "resnet2 = torchvision.models.resnet18(pretrained=False)\n",
    "num_ftrs = resnet2.fc.in_features\n",
    "resnet2.fc = nn.Sequential()\n",
    "\n",
    "model2 = SelectiveSequential(\n",
    "    ['act1', 'act2', 'out'],\n",
    "    {'conv32a': resnet2,\n",
    "       \n",
    "     'fc1': nn.Linear(num_ftrs, 1000),\n",
    "     'act1': nn.ReLU(True),\n",
    "     #'drop1': nn.Dropout(.05),\n",
    "     'fc2': nn.Linear(1000, 1000),\n",
    "     'act2': nn.ReLU(True),\n",
    "     #'drop1': nn.Dropout(.05),\n",
    "     'out': nn.Linear(1000, 10)})\n",
    "\n",
    "model2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = SelectiveSequential(\n",
    "    ['act64', 'act1', 'out'],\n",
    "    {'conv64': nn.Conv2d(3, 64, kernel_size=5, padding=2),\n",
    "     'act64': nn.ReLU(True),\n",
    "     \n",
    "     'max1': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'conv192': nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "     'act192': nn.ReLU(True),\n",
    "    \n",
    "     'max2': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'conv384': nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "     'act384': nn.ReLU(True),\n",
    "     \n",
    "     'conv256a': nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "     'act256a': nn.ReLU(True),\n",
    "     \n",
    "     'conv256b': nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "     'act256b': nn.ReLU(True),\n",
    "     \n",
    "     'max3': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     # 'avgpool': nn.AdaptiveAvgPool2d((6, 6)),\n",
    "    \n",
    "     'flatten': Flatten(),\n",
    "     'fc1': nn.Linear(4 * 4 * 256, 2048),\n",
    "     'act1': nn.ReLU(True),\n",
    "     'fc2': nn.Linear(2048, 2048),\n",
    "     'act2': nn.ReLU(True),\n",
    "     'out': nn.Linear(2048, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = TripletRegularizedCrossEntropyLoss(0.1, .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess = Session(model2, criterion, optim.AdamW, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# lr_find(sess, trainloader, start_lr=1e-12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sess.set_lr(1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "validator2 = EmbeddingSpaceValidator(valloader, 2, CustomOneHotAccuracy)\n",
    "lr_scheduler2 = CosAnneal(len(trainloader), T_mult=1, lr_min=1e-7)\n",
    "schedule2 = TrainingSchedule(trainloader, [validator2])\n",
    "sess.train(schedule2, 63)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validator2.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(np.max(validator2.val_accuracies), \"Best accuracy with reg\")\n",
    "print(np.max(validator.val_accuracies), \"Best accuracy without reg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
