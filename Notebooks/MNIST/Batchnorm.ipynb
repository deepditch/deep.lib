{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from Models.selective_sequential import *\n",
    "from Loss.triplet_regularized import *\n",
    "from session import *\n",
    "from LR_Schedule.cyclical import Cyclical\n",
    "from LR_Schedule.cos_anneal import CosAnneal\n",
    "from LR_Schedule.lr_find import lr_find\n",
    "from callbacks import *\n",
    "from validation import *\n",
    "import Datasets.ImageData as ImageData\n",
    "from Transforms.ImageTransforms import *\n",
    "import util\n",
    "from session import LossMeter, EvalModel\n",
    "from Layers.flatten import Flatten\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = datasets.MNIST('/media/drake/MX500/Datasets/mnist/train', download=True, train=True, transform=transform)\n",
    "partial_trainset = torch.utils.data.dataset.Subset(trainset, np.arange(1000))\n",
    "\n",
    "valset = datasets.MNIST('/media/drake/MX500/Datasets/mnist/test', download=True, train=False, transform=transform)\n",
    "partial_valset = torch.utils.data.dataset.Subset(valset, np.arange(1000))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = ['max1', 'act1', 'out']\n",
    "model = SelectiveSequential(\n",
    "    select,\n",
    "    {'conv64': nn.Conv2d(1, 64, kernel_size=5, padding=2),\n",
    "     'bn64': nn.BatchNorm2d(num_features=64),\n",
    "     'act64': nn.ReLU(True),\n",
    "     \n",
    "     'max1': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'conv192': nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "     'bn192': nn.BatchNorm2d(num_features=192),\n",
    "     'act192': nn.ReLU(True),\n",
    "    \n",
    "     'max2': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'conv384': nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "     'bn384': nn.BatchNorm2d(num_features=384),\n",
    "     'act384': nn.ReLU(True),\n",
    "     \n",
    "     'conv256a': nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "     'bn256a': nn.BatchNorm2d(num_features=256),\n",
    "     'act256a': nn.ReLU(True),\n",
    "     \n",
    "     'conv256b': nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "     'bn256b': nn.BatchNorm2d(num_features=256),\n",
    "     'act256b': nn.ReLU(True),\n",
    "     \n",
    "     'max3': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'flatten': Flatten(),\n",
    "     'fc1': nn.Linear(3 * 3 * 256, 512),\n",
    "     'act1': nn.ReLU(True),\n",
    "     'fc2': nn.Linear(512, 512),\n",
    "     'act2': nn.ReLU(True),\n",
    "     'out': nn.Linear(512, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/torch/cuda/__init__.py:135: UserWarning: \n",
      "    Found GPU0 GeForce GTX 770 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "criterion = TripletRegularizedMultiMarginLoss(0, .5, [])\n",
    "sess = Session(model, criterion, optim.Adam, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=70\n",
    "validator = EmbeddingSpaceValidator(valloader, select, CustomOneHotAccuracy)\n",
    "lr_scheduler = CosAnneal(len(trainloader)*num_epochs, T_mult=1, lr_min=1e-6)\n",
    "schedule = TrainingSchedule(trainloader, num_epochs, [lr_scheduler, validator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bacd37cf811944cf9db9d3a89c3feb8e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=70, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c8cacc11081545a2830512ba5974e8e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Steps', max=938, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess.train(schedule, \"./test.ckpt.tar\", reset=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.load(\"./batchnorm.ckpt.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False)\n",
    "total_validator = EmbeddingSpaceValidator(total_valloader, len(select)-1, CustomOneHotAccuracy)\n",
    "\n",
    "total_validator.run(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(total_validator.val_accuracies), \"Best accuracy without reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_set = torch.utils.data.dataset.Subset(valset, np.arange(500))\n",
    "dataloader = torch.utils.data.DataLoader(visualization_set, batch_size=64, shuffle=False)\n",
    "\n",
    "tensorboard_embeddings(model, ['max1'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')\n",
    "\n",
    "tensorboard_embeddings(model, ['max2'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')\n",
    "\n",
    "tensorboard_embeddings(model, ['max3'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')\n",
    "\n",
    "tensorboard_embeddings(model, ['act1'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')\n",
    "\n",
    "tensorboard_embeddings(model, ['act2'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')\n",
    "\n",
    "tensorboard_embeddings(model, ['out'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
