{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['',\n",
       " '/anaconda3/envs/pytorch/lib/python27.zip',\n",
       " '/anaconda3/envs/pytorch/lib/python2.7',\n",
       " '/anaconda3/envs/pytorch/lib/python2.7/plat-darwin',\n",
       " '/anaconda3/envs/pytorch/lib/python2.7/plat-mac',\n",
       " '/anaconda3/envs/pytorch/lib/python2.7/plat-mac/lib-scriptpackages',\n",
       " '/anaconda3/envs/pytorch/lib/python2.7/lib-tk',\n",
       " '/anaconda3/envs/pytorch/lib/python2.7/lib-old',\n",
       " '/anaconda3/envs/pytorch/lib/python2.7/lib-dynload',\n",
       " '/anaconda3/envs/pytorch/lib/python2.7/site-packages',\n",
       " '/Users/moncur/Documents/deep.ditch/deep.lib',\n",
       " '/anaconda3/envs/pytorch/lib/python2.7/site-packages/torchvision-0.2.1-py2.7.egg',\n",
       " '/anaconda3/envs/pytorch/lib/python2.7/site-packages/IPython/extensions',\n",
       " '/Users/moncur/.ipython']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "sys.path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "asdf\n"
     ]
    }
   ],
   "source": [
    "print \"asdf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named Models.selective_sequential",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-516acbb2f2ad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorchvision\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtransforms\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mModels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselective_sequential\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mLoss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtriplet_regularized\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msession\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named Models.selective_sequential"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from Models.selective_sequential import *\n",
    "from Loss.triplet_regularized import *\n",
    "from session import *\n",
    "from LR_Schedule.cyclical import Cyclical\n",
    "from LR_Schedule.cos_anneal import CosAnneal\n",
    "from LR_Schedule.lr_find import lr_find\n",
    "from callbacks import *\n",
    "from validation import *\n",
    "import Datasets.ImageData as ImageData\n",
    "from Transforms.ImageTransforms import *\n",
    "import util\n",
    "from session import LossMeter, EvalModel\n",
    "from Layers.flatten import Flatten\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = datasets.MNIST('/media/drake/MX500/Datasets/mnist/train', download=True, train=True, transform=transform)\n",
    "partial_trainset = torch.utils.data.dataset.Subset(trainset, np.arange(1000))\n",
    "\n",
    "valset = datasets.MNIST('/media/drake/MX500/Datasets/mnist/test', download=True, train=False, transform=transform)\n",
    "partial_valset = torch.utils.data.dataset.Subset(valset, np.arange(1000))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = ['max1', 'act1', 'out']\n",
    "model = SelectiveSequential(\n",
    "    select,\n",
    "    {'conv64': nn.Conv2d(1, 64, kernel_size=5, padding=2),\n",
    "     'bn64': nn.BatchNorm2d(num_features=64),\n",
    "     'act64': nn.ReLU(True),\n",
    "     \n",
    "     'max1': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'conv192': nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "     'bn192': nn.BatchNorm2d(num_features=192),\n",
    "     'act192': nn.ReLU(True),\n",
    "    \n",
    "     'max2': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'conv384': nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "     'bn384': nn.BatchNorm2d(num_features=384),\n",
    "     'act384': nn.ReLU(True),\n",
    "     \n",
    "     'conv256a': nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "     'bn256a': nn.BatchNorm2d(num_features=256),\n",
    "     'act256a': nn.ReLU(True),\n",
    "     \n",
    "     'conv256b': nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "     'bn256b': nn.BatchNorm2d(num_features=256),\n",
    "     'act256b': nn.ReLU(True),\n",
    "     \n",
    "     'max3': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'flatten': Flatten(),\n",
    "     'fc1': nn.Linear(3 * 3 * 256, 512),\n",
    "     'act1': nn.ReLU(True),\n",
    "     'fc2': nn.Linear(512, 512),\n",
    "     'act2': nn.ReLU(True),\n",
    "     'out': nn.Linear(512, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = TripletRegularizedMultiMarginLoss(0, .5, [])\n",
    "sess = Session(model, criterion, optim.Adam, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs=70\n",
    "validator = EmbeddingSpaceValidator(valloader, select, CustomOneHotAccuracy, \n",
    "                                    model_file=\"./batchnorm.ckpt.tar\")\n",
    "lr_scheduler = CosAnneal(len(trainloader)*num_epochs, T_mult=1, lr_min=1e-6)\n",
    "schedule = TrainingSchedule(trainloader, [lr_scheduler, validator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess.train(schedule, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.load(\"./batchnorm.ckpt.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False)\n",
    "total_validator = EmbeddingSpaceValidator(total_valloader, len(select)-1, CustomOneHotAccuracy)\n",
    "\n",
    "total_validator.run(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.max(total_validator.val_accuracies), \"Best accuracy without reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_set = torch.utils.data.dataset.Subset(valset, np.arange(500))\n",
    "dataloader = torch.utils.data.DataLoader(visualization_set, batch_size=64, shuffle=False)\n",
    "\n",
    "tensorboard_embeddings(model, ['max1'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')\n",
    "\n",
    "tensorboard_embeddings(model, ['max2'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')\n",
    "\n",
    "tensorboard_embeddings(model, ['max3'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')\n",
    "\n",
    "tensorboard_embeddings(model, ['act1'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')\n",
    "\n",
    "tensorboard_embeddings(model, ['act2'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')\n",
    "\n",
    "tensorboard_embeddings(model, ['out'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_batchnorm')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (pytorch)",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
