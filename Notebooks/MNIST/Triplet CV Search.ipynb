{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms, models\n",
    "from Models.selective_sequential import *\n",
    "from Loss.triplet_regularized import *\n",
    "from session import *\n",
    "from LR_Schedule.lr_decay import LearningRateDecay\n",
    "from LR_Schedule.lr_find import lr_find\n",
    "from callbacks import *\n",
    "from validation import *\n",
    "import Datasets.ImageData as ImageData\n",
    "from Transforms.ImageTransforms import *\n",
    "import util\n",
    "from session import LossMeter, EvalModel\n",
    "from Layers.flatten import Flatten\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from pathlib import Path\n",
    "import os, sys\n",
    "from callbacks import TrainCallback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "data = datasets.MNIST('D:\\Datasets\\mnist\\train', download=True, train=True, transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "select = ['act1', 'act2', 'out']\n",
    "\n",
    "def make_model(dropout=False, batchnorm=False):\n",
    "    return SelectiveSequential(\n",
    "    select,\n",
    "    {'conv64': nn.Conv2d(1, 64, kernel_size=5, padding=2),\n",
    "     'bn64': nn.BatchNorm2d(num_features=64) if batchnorm else Identity(),\n",
    "     'act64': nn.ReLU(True),\n",
    "\n",
    "     'max1': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "     'drop-64': nn.Dropout(.05) if dropout else Identity(),  \n",
    "    \n",
    "     'conv192': nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "     'bn192': nn.BatchNorm2d(num_features=192) if batchnorm else Identity(),\n",
    "     'act192': nn.ReLU(True),   \n",
    "\n",
    "     'max2': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "     'drop-192': nn.Dropout(.1) if dropout else Identity(),\n",
    "    \n",
    "     'conv384': nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "     'bn384': nn.BatchNorm2d(num_features=384) if batchnorm else Identity(),\n",
    "     'act384': nn.ReLU(True),\n",
    "     'drop-384': nn.Dropout(.15) if dropout else Identity(),\n",
    "     \n",
    "     'conv256a': nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "     'bn256a': nn.BatchNorm2d(num_features=256) if batchnorm else Identity(),\n",
    "     'act256a': nn.ReLU(True),\n",
    "     'drop-256a': nn.Dropout(.1) if dropout else Identity(),\n",
    "     \n",
    "     'conv256b': nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "     'bn256b': nn.BatchNorm2d(num_features=256) if batchnorm else Identity(),\n",
    "     'act256b': nn.ReLU(True),\n",
    "\n",
    "     'max3': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "     'drop-256b': nn.Dropout(.1) if dropout else Identity(),\n",
    "    \n",
    "     'flatten': Flatten(),\n",
    "\n",
    "     'fc1': nn.Linear(3 * 3 * 256, 512),\n",
    "     'act1': nn.ReLU(True),\n",
    "     'drop-fc1': nn.Dropout(.05) if dropout else Identity(),\n",
    "\n",
    "     'fc2': nn.Linear(512, 512),\n",
    "     'act2': nn.ReLU(True),\n",
    "     'drop-fc2': nn.Dropout(.05) if dropout else Identity(),\n",
    "\n",
    "     'out': nn.Linear(512, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AccuracyValidator(TrainCallback):\n",
    "    def __init__(self, val_data, accuracy_meter_fn):\n",
    "        self.val_data = val_data\n",
    "        self.val_accuracy_meter = accuracy_meter_fn()\n",
    "        self.val_accuracies = []\n",
    "\n",
    "    def run(self, session):\n",
    "        self.val_accuracy_meter.reset()\n",
    "        \n",
    "        with EvalModel(session.model):\n",
    "            for input, label, *_ in self.val_data:\n",
    "                label = Variable(util.to_gpu(label))\n",
    "                output = session.forward(input)\n",
    "                \n",
    "                self.val_accuracy_meter.update(output, label)\n",
    "         \n",
    "        accuracy = self.val_accuracy_meter.accuracy()\n",
    "        \n",
    "        self.val_accuracies.append(accuracy)  \n",
    "        \n",
    "    def on_epoch_end(self, session, lossMeter):        \n",
    "        self.run(session) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_sess(sess, trainloader, testloader):\n",
    "    \"\"\"\n",
    "    Training helper function for consistent experiments\n",
    "    \"\"\"\n",
    "    num_epochs = 30\n",
    "    validator = AccuracyValidator(testloader, CustomOneHotAccuracy)\n",
    "    lr_scheduler = LearningRateDecay(len(trainloader)*num_epochs, intervals=[25/30, 5/30], lrs=[.05, .01])\n",
    "    schedule = TrainingSchedule(trainloader, num_epochs, [lr_scheduler, validator])\n",
    "    sess.train(schedule)\n",
    "    return np.max(validator.val_accuracies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def k_fold(n, k):\n",
    "    \"\"\"\n",
    "    Creates a list of ranges that partitions n samples into k folds\n",
    "    \"\"\"\n",
    "    delt = n // k\n",
    "    remainder = n % k\n",
    "    ranges = []\n",
    "    \n",
    "    idx = 0\n",
    "    \n",
    "    for i in range(k):    \n",
    "        prev_idx = idx\n",
    "        \n",
    "        idx += delt\n",
    "        \n",
    "        if remainder != 0:         \n",
    "            remainder -= 1\n",
    "            idx += 1\n",
    "        \n",
    "        val = np.arange(prev_idx, idx)\n",
    "        train = np.setdiff1d(np.arange(0, n), val)\n",
    "        \n",
    "        ranges.append((train, val))\n",
    "                               \n",
    "    return ranges"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [0, .05, .1, .15, .2, .25, .3, .35, .4]\n",
    "folds = k_fold(len(data), 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "accuracies = {}\n",
    "\n",
    "for param in params:\n",
    "    accs = []\n",
    "       \n",
    "    for idx, fold in enumerate(folds): \n",
    "        train, val = fold\n",
    "        trainset = torch.utils.data.dataset.Subset(data, train)\n",
    "        valset   = torch.utils.data.dataset.Subset(data, val)\n",
    "        \n",
    "        trainloader = torch.utils.data.DataLoader(trainset, batch_size=128, shuffle=True)\n",
    "        valloader   = torch.utils.data.DataLoader(valset, batch_size=128, shuffle=False)\n",
    "        \n",
    "        model = make_model(dropout=False, batchnorm=False)\n",
    "        criterion = TripletRegularizedMultiMarginLoss(param, .5, select, triplet_loss_fn=batch_all_triplet_loss)\n",
    "        sess = Session(model, criterion, optim.SGD, 1e-4, log=False)\n",
    "        \n",
    "        acc = train_sess(sess, trainloader, valloader)\n",
    "        \n",
    "        accs.append(acc)\n",
    "      \n",
    "    accuracies[param] = {\"mean\": np.mean(accs), \"folds\": accs}\n",
    "    \n",
    "    df = pd.DataFrame(accuracies)\n",
    "    df.to_csv(\"./MNIST-CV.csv\")\n",
    "        \n",
    "    print(f\"Lambda={param} Mean={round(np.mean(accs), 2)} \")\n",
    "    \n",
    "    for acc in accs:\n",
    "        print(f\"    {round(acc, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
