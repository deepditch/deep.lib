{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from Models.selective_sequential import *\n",
    "from Loss.triplet_regularized import *\n",
    "from session import *\n",
    "from LR_Schedule.cyclical import Cyclical\n",
    "from LR_Schedule.cos_anneal import CosAnneal\n",
    "from LR_Schedule.lr_find import lr_find\n",
    "from callbacks import *\n",
    "from validation import *\n",
    "import Datasets.ImageData as ImageData\n",
    "from Transforms.ImageTransforms import *\n",
    "import util\n",
    "from session import LossMeter, EvalModel\n",
    "from Layers.flatten import Flatten\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/drake/anaconda3/envs/.torch/lib/python3.7/site-packages/torch/cuda/__init__.py:135: UserWarning: \n",
      "    Found GPU0 GeForce GTX 770 which is of cuda capability 3.0.\n",
      "    PyTorch no longer supports this GPU because it is too old.\n",
      "    The minimum cuda capability that we support is 3.5.\n",
      "    \n",
      "  warnings.warn(old_gpu_warn % (d, name, major, capability[1]))\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.set_device(0); torch.backends.cudnn.benchmark=True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = datasets.MNIST('/media/drake/MX500/Datasets/mnist/train', download=True, train=True, transform=transform)\n",
    "partial_trainset = torch.utils.data.dataset.Subset(trainset, np.arange(500))\n",
    "\n",
    "valset = datasets.MNIST('/media/drake/MX500/Datasets/mnist/test', download=True, train=False, transform=transform)\n",
    "partial_valset = torch.utils.data.dataset.Subset(valset, np.arange(500))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(partial_trainset, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(partial_valset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Identity(nn.Module):\n",
    "    def __init__(self, *args, **kwargs):\n",
    "        super().__init__()\n",
    "    def forward(self, x):\n",
    "        return x\n",
    "\n",
    "select = ['act1', 'act2', 'out']\n",
    "\n",
    "def make_model(dropout=False, batchnorm=False):\n",
    "    return SelectiveSequential(\n",
    "    select,\n",
    "    {'conv64': nn.Conv2d(1, 64, kernel_size=5, padding=2),\n",
    "     'bn64': nn.BatchNorm2d(num_features=64) if batchnorm else Identity(),\n",
    "     'act64': nn.ReLU(True),\n",
    "\n",
    "     'max1': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "     'drop-64': nn.Dropout(.05) if dropout else Identity(),  \n",
    "    \n",
    "     'conv192': nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "     'bn192': nn.BatchNorm2d(num_features=192) if batchnorm else Identity(),\n",
    "     'act192': nn.ReLU(True),   \n",
    "\n",
    "     'max2': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "     'drop-192': nn.Dropout(.1) if dropout else Identity(),\n",
    "    \n",
    "     'conv384': nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "     'bn384': nn.BatchNorm2d(num_features=384) if batchnorm else Identity(),\n",
    "     'act384': nn.ReLU(True),\n",
    "     'drop-384': nn.Dropout(.15) if dropout else Identity(),\n",
    "     \n",
    "     'conv256a': nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "     'bn256a': nn.BatchNorm2d(num_features=256) if batchnorm else Identity(),\n",
    "     'act256a': nn.ReLU(True),\n",
    "     'drop-256a': nn.Dropout(.1) if dropout else Identity(),\n",
    "     \n",
    "     'conv256b': nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "     'bn256b': nn.BatchNorm2d(num_features=256) if batchnorm else Identity(),\n",
    "     'act256b': nn.ReLU(True),\n",
    "\n",
    "     'max3': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "     'drop-256b': nn.Dropout(.1) if dropout else Identity(),\n",
    "    \n",
    "     'flatten': Flatten(),\n",
    "\n",
    "     'fc1': nn.Linear(3 * 3 * 256, 512),\n",
    "     'act1': nn.ReLU(True),\n",
    "     'drop-fc1': nn.Dropout(.05) if dropout else Identity(),\n",
    "\n",
    "     'fc2': nn.Linear(512, 512),\n",
    "     'act2': nn.ReLU(True),\n",
    "     'drop-fc2': nn.Dropout(.05) if dropout else Identity(),\n",
    "\n",
    "     'out': nn.Linear(512, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = TripletRegularizedMultiMarginLoss(.5, .5, select)\n",
    "sess = Session(make_model(False, False), criterion, optim.Adam, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_epochs = 50\n",
    "# validator = EmbeddingSpaceValidator(valloader, select, CustomOneHotAccuracy, \n",
    "#                                    model_file=\"./triplet-reg.ckpt.tar\")\n",
    "# lr_scheduler = CosAnneal(len(trainloader)*50, T_mult=1, lr_min=1e-6)\n",
    "# schedule = TrainingSchedule(trainloader, [lr_scheduler, validator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# sess.train(schedule, 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validator.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.load(\"./all-triplet-reg-MNIST-fulldata-2.ckpt.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', max=157, style=ProgressStyle(description_width='â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r"
     ]
    }
   ],
   "source": [
    "total_valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False)\n",
    "total_validator = EmbeddingSpaceValidator(total_valloader, [], CustomOneHotAccuracy)\n",
    "\n",
    "total_validator.run(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9949, 'Best accuracy without reg')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(total_validator.val_accuracies), \"Best accuracy without reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_set = torch.utils.data.dataset.Subset(valset, np.arange(500))\n",
    "dataloader = torch.utils.data.DataLoader(visualization_set, batch_size=64, shuffle=False)\n",
    "\n",
    "tensorboard_embeddings(sess.model, ['max1'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_all_tripletreg')\n",
    "\n",
    "tensorboard_embeddings(sess.model, ['max2'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_all_tripletreg')\n",
    "\n",
    "tensorboard_embeddings(sess.model, ['max3'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_all_tripletreg')\n",
    "\n",
    "tensorboard_embeddings(sess.model, ['act1'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_all_tripletreg')\n",
    "\n",
    "tensorboard_embeddings(sess.model, ['act2'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_all_tripletreg')\n",
    "\n",
    "tensorboard_embeddings(sess.model, ['out'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_all_tripletreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
