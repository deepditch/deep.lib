{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from Models.selective_sequential import *\n",
    "from Loss.triplet_regularized import *\n",
    "from session import *\n",
    "from LR_Schedule.cyclical import Cyclical\n",
    "from LR_Schedule.cos_anneal import CosAnneal\n",
    "from LR_Schedule.lr_find import lr_find\n",
    "from callbacks import *\n",
    "from validation import *\n",
    "import Datasets.ImageData as ImageData\n",
    "from Transforms.ImageTransforms import *\n",
    "import util\n",
    "from session import LossMeter, EvalModel\n",
    "from Layers.flatten import Flatten\n",
    "from torch.utils.tensorboard import SummaryWriter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "torch.cuda.set_device(0); torch.backends.cudnn.benchmark=True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "trainset = datasets.MNIST('/media/drake/MX500/Datasets/mnist/train', download=True, train=True, transform=transform)\n",
    "partial_trainset = torch.utils.data.dataset.Subset(trainset, np.arange(1000))\n",
    "\n",
    "valset = datasets.MNIST('/media/drake/MX500/Datasets/mnist/test', download=True, train=False, transform=transform)\n",
    "partial_valset = torch.utils.data.dataset.Subset(valset, np.arange(1000))\n",
    "\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=64, shuffle=True)\n",
    "valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "select = ['max1', 'act1', 'out']\n",
    "model = SelectiveSequential(\n",
    "    select,\n",
    "    {'conv64': nn.Conv2d(1, 64, kernel_size=5, padding=2),\n",
    "     'act64': nn.ReLU(True),\n",
    "     \n",
    "     'max1': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'conv192': nn.Conv2d(64, 192, kernel_size=5, padding=2),\n",
    "     'act192': nn.ReLU(True),\n",
    "    \n",
    "     'max2': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'conv384': nn.Conv2d(192, 384, kernel_size=3, padding=1),\n",
    "     'act384': nn.ReLU(True),\n",
    "     \n",
    "     'conv256a': nn.Conv2d(384, 256, kernel_size=3, padding=1),\n",
    "     'act256a': nn.ReLU(True),\n",
    "     \n",
    "     'conv256b': nn.Conv2d(256, 256, kernel_size=3, padding=1),\n",
    "     'act256b': nn.ReLU(True),\n",
    "     \n",
    "     'max3': nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "    \n",
    "     'flatten': Flatten(),\n",
    "     'fc1': nn.Linear(3 * 3 * 256, 512),\n",
    "     'act1': nn.ReLU(True),\n",
    "     'fc2': nn.Linear(512, 512),\n",
    "     'act2': nn.ReLU(True),\n",
    "     'out': nn.Linear(512, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = TripletRegularizedMultiMarginLoss(0, .5, select)\n",
    "sess = Session(model, criterion, optim.Adam, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 50\n",
    "validator = EmbeddingSpaceValidator(valloader, select, CustomOneHotAccuracy, \n",
    "                                    model_file=\"./no-reg.ckpt.tar\")\n",
    "lr_scheduler = CosAnneal(len(trainloader)*num_epochs, T_mult=1, lr_min=1e-6)\n",
    "schedule = TrainingSchedule(trainloader, [lr_scheduler, validator])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d29f9bb194be433db889cff30acf3da7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epochs', max=50, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Steps', max=938, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "44aec560fd1e4c32be2e0b3a68bd2b8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', max=157, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "val accuracy:  0.9692 \n",
      "train loss:  0.0089  train BCE :  0.0557 \n",
      "valid loss:  0.0106  valid BCE :  0.0106\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e08b6f6af1484a6fb847ade636ff018e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Steps', max=938, style=ProgressStyle(description_width='initi…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sess.train(schedule, num_epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "validator.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "sess.load(\"./no-reg.ckpt.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "457ba3f8127a45be80d7d5db1eae8cbb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Validating', max=157, style=ProgressStyle(description_width='…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "total_valloader = torch.utils.data.DataLoader(valset, batch_size=64, shuffle=False)\n",
    "total_validator = EmbeddingSpaceValidator(total_valloader, [], CustomOneHotAccuracy)\n",
    "\n",
    "total_validator.run(sess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.7377, 'Best accuracy without reg')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.max(total_validator.val_accuracies), \"Best accuracy without reg\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualization_set = torch.utils.data.dataset.Subset(valset, np.arange(500))\n",
    "dataloader = torch.utils.data.DataLoader(visualization_set, batch_size=64, shuffle=False)\n",
    "\n",
    "tensorboard_embeddings(model, ['max1'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_noreg')\n",
    "\n",
    "tensorboard_embeddings(model, ['max2'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_noreg')\n",
    "\n",
    "tensorboard_embeddings(model, ['max3'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_noreg')\n",
    "\n",
    "tensorboard_embeddings(model, ['act1'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_noreg')\n",
    "\n",
    "tensorboard_embeddings(model, ['act2'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_noreg')\n",
    "\n",
    "tensorboard_embeddings(model, ['out'], \n",
    "                       dataloader, \n",
    "                       valset.targets[:500], \n",
    "                       1.0 - valset.data[:500].reshape(-1, 1, 28, 28) / 255.0, \n",
    "                       './mnist_noreg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
