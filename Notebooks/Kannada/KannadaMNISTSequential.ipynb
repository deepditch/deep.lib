{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torchvision import datasets, transforms\n",
    "from torch import nn, optim\n",
    "from torch.nn.modules.loss import *\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "from sklearn.decomposition import PCA\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from Loss.triplet import *\n",
    "from session import *\n",
    "from LR_Schedule.cyclical import Cyclical\n",
    "from LR_Schedule.cos_anneal import CosAnneal\n",
    "from LR_Schedule.lr_find import lr_find\n",
    "from callbacks import *\n",
    "from validation import *\n",
    "from validation import _AccuracyMeter\n",
    "import Datasets.ImageData as ImageData\n",
    "from Transforms.ImageTransforms import *\n",
    "import util\n",
    "import Datasets.ModelData as md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.set_device(0); torch.backends.cudnn.benchmark=True;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = Path(\"/media/drake/MX500/Datasets/Kannada-MNIST\")\n",
    "train_path = data_path/'train.csv'\n",
    "test_path = data_path/'test.csv'\n",
    "df = pd.read_csv(train_path)\n",
    "test_df = pd.read_csv(test_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = df[df.columns[0]].to_numpy()\n",
    "inputs = df[df.columns[1:]].to_numpy().reshape(-1, 28, 28)\n",
    "\n",
    "ids = test_df[test_df.columns[0]].to_numpy()\n",
    "test_inputs = test_df[test_df.columns[1:]].to_numpy().reshape(-1, 28, 28)\n",
    "\n",
    "inputs.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class KannadaMNISTDataset(Dataset):\n",
    "    def __init__(self, inputs, labels, transform):\n",
    "        self.data = inputs\n",
    "        self.targets = labels\n",
    "        self.tsfm = transform\n",
    "        \n",
    "    def __len__(self): return self.targets.shape[0]\n",
    "        \n",
    "    def __getitem__(self, i):\n",
    "        x, y = self.data[i], self.targets[i]  \n",
    "        x = x.astype(np.uint8)\n",
    "        x = self.tsfm(x)\n",
    "        x = x.float()\n",
    "        \n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_dict = md.make_partition_indices(labels.shape[0], {'train': .9, 'valid': .1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                transforms.RandomRotation(9),\n",
    "                                transforms.RandomResizedCrop(28, scale=(.95, 1.05)),\n",
    "                                transforms.ToTensor(), \n",
    "                                transforms.Normalize((0.5,), (0.5,))])\n",
    "\n",
    "train_dataset = KannadaMNISTDataset(inputs[i_dict['train']], labels[i_dict['train']], transform)\n",
    "valid_dataset = KannadaMNISTDataset(inputs[i_dict['valid']], labels[i_dict['valid']], transform)\n",
    "test_dataset = KannadaMNISTDataset(test_inputs, ids, transform)\n",
    "trainloader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "valloader = DataLoader(valid_dataset, batch_size=64, shuffle=False)\n",
    "testloader = DataLoader(test_dataset, batch_size=64, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Flatten(nn.Module):\n",
    "    def forward(self, input):\n",
    "        return input.view(input.size(0), -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TripletRegularizedCrossEntropyLoss(nn.Module):\n",
    "    def __init__(self, alpha, margin):     \n",
    "        super().__init__()\n",
    "        self.alpha = alpha\n",
    "        self.margin = margin\n",
    "        \n",
    "    def forward(self, x, y):\n",
    "        loss = F.cross_entropy(x[-1], y)\n",
    "        triplet = 0\n",
    "        \n",
    "        for layer in x[:-1]:\n",
    "            triplet += batch_hard_triplet_loss(layer.view(layer.size(0), -1), y, self.margin)\n",
    "            \n",
    "        # triplet *= min(self.alpha/math.sqrt(loss.item()), 1)\n",
    "        triplet *= self.alpha\n",
    "            \n",
    "        return loss + triplet\n",
    "    \n",
    "    \n",
    "class CustomOneHotAccuracy(OneHotAccuracy):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.reset()\n",
    "\n",
    "    def update(self, output, label):\n",
    "        super().update(output[-1], label)\n",
    "        \n",
    "class SelectiveSequential(nn.Module):\n",
    "    def __init__(self, to_select, modules_dict):\n",
    "        super(SelectiveSequential, self).__init__()\n",
    "        for key, module in modules_dict.items():\n",
    "            self.add_module(key, module)\n",
    "        self._to_select = to_select\n",
    "        self.output_layer = None\n",
    "    \n",
    "    def setOutputLayer(self, output_layer):\n",
    "        self.output_layer = output_layer\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # list = []\n",
    "        for name, module in self._modules.items():               \n",
    "            x = module(x)      \n",
    "            \n",
    "            if name is self.output_layer:\n",
    "                return x.view(x.size(0), -1)\n",
    "            \n",
    "            #if name in self._to_select:\n",
    "            #    list.append(x)\n",
    "                \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = SelectiveSequential(\n",
    "    ['cv1', 'cv2', 'cv3', 'cv4', 'cv5', 'cv6', 'fc1', 'fc2', 'out'],\n",
    "    {'cv1': nn.Sequential(nn.Conv2d(1, 16, kernel_size=3, stride=1, padding=1), \n",
    "                          nn.BatchNorm2d(16), \n",
    "                          nn.ReLU()),\n",
    "     'cv2': nn.Sequential(nn.Conv2d(16, 32, kernel_size=3, stride=1, padding=1), \n",
    "                          nn.BatchNorm2d(32), \n",
    "                          nn.ReLU()),\n",
    "     'cv3': nn.Sequential(nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                          nn.Conv2d(32, 64, kernel_size=5, stride=1, padding=2),\n",
    "                          nn.BatchNorm2d(64), \n",
    "                          nn.ReLU()),\n",
    "     'cv4': nn.Sequential(nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "                          nn.Conv2d(64, 128, kernel_size=5, stride=1, padding=2),\n",
    "                          nn.BatchNorm2d(128), \n",
    "                          nn.ReLU()),\n",
    "     'cv5': nn.Sequential(nn.Conv2d(128, 64, kernel_size=3, stride=1, padding=1),\n",
    "                          nn.BatchNorm2d(64), \n",
    "                          nn.ReLU()),  \n",
    "     'cv6': nn.Sequential(nn.Conv2d(64, 32, kernel_size=3, stride=1, padding=1),\n",
    "                          nn.BatchNorm2d(32), \n",
    "                          nn.ReLU()),\n",
    "    \n",
    "     'fc1': nn.Sequential(Flatten(), \n",
    "                          nn.Linear(7 * 7 * 32, 50)),\n",
    "     'fc2': nn.Linear(50, 25),\n",
    "     'out': nn.Linear(25, 10)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer, idx in zip(['cv1', 'cv2', 'cv3', 'cv4', 'cv5', 'cv6', 'fc1', 'fc2'], range(8)):\n",
    "    model.setOutputLayer(layer)\n",
    "    sess = Session(model, BatchHardTripletLoss(.5), optim.Adam, 1e-4)\n",
    "    sess.freeze_to(idx)\n",
    "    validator = Validator(valloader)\n",
    "    schedule = TrainingSchedule(trainloader, [validator])\n",
    "    sess.train(schedule, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.setOutputLayer('out')\n",
    "sess = Session(model, nn.CrossEntropyLoss(), optim.Adam, 1e-4)\n",
    "sess.freeze()\n",
    "lr_scheduler = CosAnneal(len(trainloader), T_mult=2)\n",
    "validator = Validator(valloader, OneHotAccuracy(), save_best=True, model_dir='./triplet')\n",
    "schedule = TrainingSchedule(trainloader, [lr_scheduler, validator])\n",
    "sess.train(schedule, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "sess = Session(model, nn.CrossEntropyLoss(), optim.Adam, 1e-4)\n",
    "sess.unfreeze()\n",
    "lr_scheduler = CosAnneal(len(trainloader), T_mult=2)\n",
    "validator = Validator(valloader, OneHotAccuracy(), save_best=True, model_dir='./triplet')\n",
    "schedule = TrainingSchedule(trainloader, [lr_scheduler, validator])\n",
    "sess.train(schedule, 7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with EvalModel(model):\n",
    "    sample = model.forward(util.to_gpu(torch.randn(64, 1, 28, 28)))\n",
    "    print(sample.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
